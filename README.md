# DLAI2
## Домашнее задание к уроку 2: Линейная и логистическая регрессия
### Задание 1: Модификация существующих моделей
1. Потренироавлся в создании простых кастомных моделей на основе базовых.
2. В линейной регрессии добавил L1 и L2 регуляризацию и возможность ранней остановки.
3. В логистической регрессии добавил поддержку многоклассовой классификации. 
4. Реализовал различные метрики и добавил визуализацию матрицы ошибок.

Пример матрицы:

![confusion_matrix.png](plots%2Ftest_matrix%2Fconfusion_matrix.png)

### Задание 2: Работа с датасетами
1. Создал кастомный класс датасета для работа с csv файлами.
2. Протестировал работу ранее созданных классов моделей.
3. Обученные модели можно найти в папке models/.
### Задание 3: Эксперименты и анализ
1. Поэкспериментировал с различными гиперпараметрами моделей. Ниже представлены графики результатов экспериментов и их анализ.
2. Поэкспериментировал с созданием новых признаков из старых с помощью следующих способов:
   - Полиномиальные признаки
   - Взаимодействия между признаками
   - Статистические признаки (среднее, дисперсия)

**Результаты экспериментов**

**Классификация:**

![hyperparameter_results_classification.png](plots%2Fhyperparameter_results_classification.png)

Можно сделать следующие выводы:
1. Оптимизатор SGD чаще всего оказывался значительно хуже других. Это можно объяснить тем, что для него может требоваться больший learning rate, так как с его увеличением графики постепенно выравниваются.
2. Оптимизатор Adam чаще других оказывался лучше всех. Это можно объяснить тем, что он наиболее универсален. Так же он имеет лучший результат среди всех при learning rate = 0.1 и batch size = 32.
3. Так же можно сказать, что среди протестированных, чем больше batch size, тем лучше качество.

**Регрессия:**

![hyperparameter_results_regression.png](plots%2Fhyperparameter_results_regression.png)

Можно сделать следующие выводы:
1. Оптимизатор SGD опять чаще всего оказывался хуже других
2. Очень мало моделей сошлось на этих данных. Лишь некоторым удалось достигнуть отметки ниже 900.
3. Лучший результат у RMSprop при learning rate = 0.1 и batch size = 16. 

Так же я проводил эксперименты с различными признаками.

Так получились следующие результаты:
 - Улучшение poly vs base: -307.20%
 - Улучшение int vs base: 60.11%
 - Улучшение stat vs base: -109.97%

**Выводы:**

 - Как можно увидеть, полиномиальные признаки значительно ухудшили качество моделей. Скорее всего проблема в том, что их слишком много и с ними нужно работать осторожнее
 - Было получено улучшение на взаимодействии между признаками.
 - Было ужудшено качество при использовании статистических данных. Вероятнее всего это произошло из-за того, что эти признаки были слишком простыми и не несли никакой полезной информации.